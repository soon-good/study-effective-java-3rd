# 8.3.2 큐에 쌓인 작업 관리

스레드 하나로 여러개의 작업을 처리하기 힘든상황이 왔을때, 스레드 풀을 사용한다는 점을 이전 장까지 살펴봤었다. 스레드 풀 없이 스레드를 계속해서 생성하는 경우 스레드마다 CPU를 확보하기 위해 대기한다. 이런 이유로 스레드 풀을 사용한다. <br>

그리고 스레드 풀이 모두 작업을 처리하기 위해 꽉 차있는 상황에서 새로운 작업 A 가 생성되면, 이 작업 A는 작업을 관리하는 큐에 보관해둔다. 이것을 주로 작업 큐라고 이야기한다. 자세한 내용들은 아래에 정리되어 있다.<br>

스레드 풀을 사용하더라도, 작업을 처리해내는 속도보다 빠른 속도로 작업이 추가될 때 작업 큐 역시도 견뎌내지 못하는 상황이 발생한다. 8.3.2 절에서는, Collector 에서 제공하는 대표적인 Executor 팩토리 메서드들이 기본적으로 가지고 있는 작업 큐들의 개별적인 특성들을 정리하고 있다.<br>

**newCachedThreadPool**<br>

newCachedThreadPool 은 주로 의존성이 있는 작업에 사용한다. 의존성 작업이 있어서 삭제 정책이나 폐기 정책을 적용하지 못하기에 스레드 풀을 무한으로 생성해 대기하도록 하는 것.

`newCachedThreadPool` 팩토리 메서드를 이용해 생성하는 Executor  객체는 스레드 풀의 크기가 고정되지 않은 스레드 풀을 가지고 있는 것이 특징이다. (8.2 절 참고, `newCachedThreadPool` 의 `maximumPoolSize` 에 설정되는 기본 값은 `Integer.MAX_VALUE` 다.)<br>

때에 따라서 크기가 고정된 pool 보다는 `newCachedThreadPool` 팩토리 메서드로 생성한 Executor 객체를 통해 크기가 고정되지 않은 스레드 풀을 사용하는 것이 오히려 더 유리할 수도 있다. 예를 들면 다른 작업에 의존성을 갖는 작업을 실행해야 할 때 스레드나 큐의 크기가 제한되어 있으면, 의존성 작업은 실행되지 못하고 계속 대기해야 하는데, 이때 스레드 부족 데드락에 걸릴 가능성이 높다.<br>

이럴 때는 스레드 풀의 크기가 제한되지 않은 풀을 사용하는 것이 오히려 낫다.<br>

하지만, 이 방식 역시 `newCachedThreadPool`을 사용하지 않는 대안이 있다. ThreadPoolExecutor 를 커스텀으로 생성하는데 아래와 같은 원칙에 따라 생성하면 된다. (개인적으로 난 커스터마이징 방식이 더 마음에 든다. 기본 설정은 그냥 빌트인으로 사용자에게 기본 옵션으로 제공해주는 것이라고 생각한다.)<br>

<br>

**ThreadPoolExecutor 객체를 직접 생성하는 방식 (커스터마이징)**

- 스레드 풀의 스레드 갯수를 제한
  - newCachedThreadPool 은 크기가 제한되지 않지만, 
- 작업 큐로 `SynchronizedQueue` 를 사용
  - `newCachedThreadPool` 처럼 `SynchronizedQueue` 를 사용한다.
- 집중 대응 정책으로 호출자 실행 전략을 사용
  - 트래픽이 집중되어 스레드 풀이 꽉 찼을 때 남아있는 스레드가 없기에 Executor 자신의 스레드를 활용해서 작업을 실행하는 방식

집중대응정책은 8.3.3절에서 정리.<br>

<br>

**newFixedThreadPool**<br>

반면, 크기가 고정된 풀을 사용하는 것은 동시에 실행되는 스레드의 수를 제한해야 하는 경우에 현명한 선택이 될 수 있다. 예를 들면 네트웍으로 클라이언트의 요청을 받아 처리하는 애플리케이션의 경우, 큐의 크기든, 스레드 풀의 크기든 크기가 고정되어 있지 않다면 요청이 많아저 부하가 걸릴때 문제가 된다. <br>

<br>

## ThreadPoolExecutor 의 스레드 풀과 작업 큐

`newCachedThreadPool` , `newFixedThreadPool` , `newSingleThreadExecutor` 메서드에서 생성하는 객체는 주로 ThreadPoolExecutor 타입의 객체로 받을 수 있다. 이 ThreadPoolExecutor 의 주요 동작원리는 이렇다.<br>

- 한번에 처리 못하는 작업들은 계속해서 `작업큐` 라는 곳에 쌓아둔다.
  -  작업을 처리할 수 있는 능력보다 많은 양의 요청이 들어오면 요청은 큐에 계속해서 쌓인다.
  - 스레드 풀을 사용하는 경우 Executor 클래스가 관리하는 큐에 `Runnable` 로 정의된 작업이 계속해서 쌓인다.
- 스레드 풀에 있는 모든 작업이 실행중일 때, 새로 들어온 작업은 큐에 넣어둔다.
  - 새로 들어오는 작업은 주로 `Runnable` 로 정의된 작업들이다. 이 작업들은 계속해서 큐에 쌓아둔다.

<br>

스레드 풀을 사용할 때에 스레드 풀을 사용하지 않는 경우에 비해 문제가 덜 발생하기는 하지만, 스레드 풀을 사용할 경우는, 큐가 꽉 찼을때의 해결방안이 필요하다.<br>

<br>

## 작업큐가 가득 찼을 경우에 대한 해결 방법들

대량의 트래픽이 갑자기 몰리는 경우는 스레드 풀과 작업 큐를 사용해 충분히 유연하게 처리할 수 있다. 이 경우 속도 조절 기능을 사용하거나, 큐에 작업을 쌓아두고 큐에 작업 관리 전략을 적용해야 한다.<br>

스레드 풀이 가득 찼을 때의 해결책은 두가지가 있다. **첫번째**는 **속도조절기능**이고, **두번째**는 **작업 큐에 작업들을 쌓아두는 방식**이다. 스레드 풀의 크기를 제한해두었을 때, 스레드 풀이 가득 차면 작업을 작업 큐에 작업들을 잠시 쌓아둘 수 있다. 이 방식을 작업큐에 작업들을 쌓아두는 방식이라고 부른다. 속도 조절 기능은 클라이언트 측에서 요청의 속도를 조절하는 방식이다.

**속도조절 기능**<br>

계속해서 처리하는 속도보다 빠른 속도로 작업이 추가될 때, 해결방책 중 하나로 책에서는 속도 조절 기능에 대해서도 언급하고 있다. 속도 조절기능은 클라이언트 측에서 속도를 느리게 조절하는 방식인데, 실생활에서는 거의 사용되지 않는 방식이다.<br>

<br>

**작업 큐에 작업들을 쌓아두기**<br>

계속해서 처리하는 속도보다 빠른 속도로 작업이 추가될 때, 또 하나의 해결 방책 중 하나는 작업 큐를 만들어서 작업 대기열처럼 사용하는 것이다. 물론 이것이 만능은 아니다. 스레드 풀이 꽉 찼을때 작업 큐에 등록되는 작업들의 양이 무한대로 늘어날 때 물리적으로 지원 가능한 메모리가 한계치에 도달할 수도 있기 때문이다. 이 경우 거부 정책을 정해서 실행하면 된다.

큐에 대한 작업관리 전략은 세가지가 있다. <br>

1 ) 큐에 크기 제한을 두지 않는 방법 <br>

2 ) 큐의 크기를 제한하는 방법 <br>

3 ) 작업을 스레드에게 직접 넘겨주는 방법 <br>

- 호출자 실행전략을 의미한다. 
- 이 부분은 나중에 정리.

<br>

## 1 ) 큐에 크기 제한을 두지 않는 방법

### newFixedThreadPool, newSingleThreadExecutor

#### 기본 설정 작업 큐, `LinkedBlockingQueue`

`newFixedThreadPool` 메서드, `newSingleThreadExecutor` 메서드에서 생성하는 스레드 풀은 기본 설정으로 크기가 제한되지 않은 `LinkedBlockingQueue`를 사용한다. 큐의 크기를 제한을 두지 않는 방식을 사용하는 것이 필요한 경우는 상당한 시간이 걸리더라도 데이터를 모두 기록해야 하거나 그런 작업들에 적합하지 않을까 싶다.<br>

스레드 풀에 있는 모든 작업이 실행 중일때 작업이 등록되면, 스레드 풀 대신 작업은 큐에 쌓이게 된다. 이때 작업이 처리되는 속도보다 작업이 추가되는 속도가 더 빠르면 큐에 끝없이 계속해서 작업이 쌓일 수 있다.<br>

이렇게 작업이 끝없이 쌓이는 문제로 인해 `OutOfMemory` 같은 에러가 발생할 수 있는데, 이런 이유로 크기가 제한된 큐를 사용하는 방식이 훨씬 안정적이다. Java 플랫폼에서 제공하고 있는 컬렉션 라이브러리들을 구체적인 예로 들어보면,  `ArrayBlockingQueue` , 크기를 제한해둔 `LinkedBlockingQueue` , `PriorityBlockingQueue` 로 크기가 제한된 큐를 적용하는 것이 안정적인 편이다.<br>

하지만, 큐에 크기 제한을 두지 않는 방식이 그렇게까지 나쁜방식은 아니다. 만약 시간이 걸리더라도 모든 특정시간 내에 무한히 오는 데이터들을 모두 처리해야 하지만, 물리적인 공간이 부족할 경우 `off-heap` 메모리 공간을 사용하도록 유도하거나, 디스크를 읽어들여서 기록해두는 방식의 큐를 사용하는 차선책을 적용하는 방법도 생각해볼 수 있을 것 같다.<br>

> 참고: 
>
> - newFixedThreadPool, newSingleThreadExecutor 는 큐의 크기가 무제한 이지만, 아래에서 살펴볼 newCachedThreadPool 은 스레드 풀의 크기가 무제한(무제한이라기 보다는 Integer.MAX_VALUE)이다.<br>
> - newFixedThreadPool, newSingleThreadExecutor 는 큐의 크기가 무제한이기에 큐의 크기를 가급적 제한된 큐를 사용하게끔 하라고 이야기 한다. 
> - 이에 비해 아래에서 살펴볼 newSingleThreadExecutor 는 스레드 풀의 크기가 무제한 이기에 커스텀한 ThreadPoolExecutor 를 생성할 때 가급적 스레드 풀의 크기를 제한하라고 한다.
> - 신기하게도, 두 종류의 팩토리 메서드의 단점을 보완하는 방식은 크기를 제한하는 방식이다. 
> - 라이브러리를 공부하는게 되어버렸는데, 나중에 스레드를 모르고 생성하는 것보다는 그래도 알고 생성한 코드를 만드는 것이 나으니... 참고서 정리중이다...

<br>

### newCachedThreadPool

> 생각해보니 책의 내용이 다소 횡설수설이라는 느낌이 들었다. 8.3.1 절의 newCachedThreadPool 팩토리 메서드에 대해 정리했던 내용도 이곳에 같이 정리해두기로 했다.



#### newCachedThreadPool 의 작업큐인 SynchronouseQueue

`newCachedThreadPool` 팩토리 메서드는 스레드 풀에 `SynchronousQueue` 를 적용하고 있다. 스레드 갯수가 굉장히 많거나 제한이 거의 없는 경우, 작업을 큐에 쌓는 절차를 생략할 수도 있다. 이런 경우 `SynchronousQueue` 를 사용해 프로듀서에서 생성한 작업을 컨슈머인 스레드에게 직접 전달한다. `newCachedThreadPool` 을 사용할 때 `SynchronouseQueue` 는 큐의 기능보다는, 스레드 간에 작업을 넘겨주는 기능을 충실히 수행한다.<br>

> 자세한 나료는 아래의 자료를 참고하자.
>
> - [백발의 개발자 - java.util.concurrent.SynchronousQueue 분석](https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=jjoommnn&logNo=130171358905)
> - [A Guide to Java - SynchronousQueue](https://www.baeldung.com/java-synchronous-queue)<br>

<br>

#### newCachedThreadPool 팩토리 메서드

> 8.3.1 절의 newCachedThreadPool 팩토리 메서드에 관련된 내용들을 이곳에 한번 더 정리하기로 했다.

<br>

`newCachedThreadPool` 의 기본 설정

- `maximumPoolSize` : `Integer.MAX_VALUE`
- `corePoolSize` : 0
- `keepAliveTime` : 1분

<br>

#### newCachedThreadPool 팩토리 메서드의 작업큐인 SynchronousQueue의 제한조건

`newCachedThreadPool` 을 사용해 생성한 `ThreadPoolExecutor` 로 스레드를 관리할 때 스레드의 갯수가 최대 크기(`maximumPoolSize`)에 도달하면 `집중 대응 정책(saturation policy)` 에 의해 작업을 거부하게 된다. `newCachedThreadPool` 팩토리 메서드가 사용하는 `SynchronizedQueue` 는 스레드 갯수를 무제한으로 늘릴 수 있는 상태이거나, 넘치는 작업이 있을 때 작업을 마음대로 거부할 수 있어야 한다. 즉, `newCachedThreadPool` 팩토리 메서드를 사용할 경우 아래와 같은 조건을 만족해야 한다.

-  스레드를 무제한으로 늘릴수 있어야 한다.
- 또는 `maximumPoolSize` 를 넘어서는 작업이 있을 경우 마음대로 거부할 수 있어야 한다.

<br>

## 2 ) 큐의 크기를 제한하는 방식

작업을 처리하는 속도보다 요청되는 작업이 추가되는 속도가 더 빠를 때 큐에 쌓아두는데, 이것을 무한히 쌓아둘 경우 메모리 부족 문제가 발생하게 된다. 여기에 대한 해결책 중 하나는 큐의 크기를 제한하고, 큐의 크기가 가득 찼을때 시간이 꽤 지난 데이터가 필요 없다고 생각될 경우 큐에서 강제로 제거하는 방식이 있다. <br>

이 방식은 데이터를 정확하게 기록하거나 하는 작업보다는 실시간으로 어떤 데이터를 계속해서 보여줘야 하는 스트리밍 등의 작업에 적합한 방식이다.<br>

<br>

**장점**<br>

크기가 제한된 큐를 사용하면 자원의 사용량을 제한시킬 수 있다는 장점이 있다. 예를 들면 `OutOfMemory` 와 같은 에러를 발생할 만한 가능성을 줄일 수 있다는 점이 장점이다.<br>

**단점**<br>

큐가 가득 찼을때 새로운 작업을 어떻게 등록해야 할지에 대한 기준을 정해야 하는 문제가 생긴다.<br>

큐에서 제거할 데이터를 추출하는 기준을 마련해야 한다.<br>

<br>

<hr/>

이번 장이 제일 힘들었다. 내용이 여기저기 퍼져 있어서 모아서 정리하는데에 꽤 애를 먹은것 같다.
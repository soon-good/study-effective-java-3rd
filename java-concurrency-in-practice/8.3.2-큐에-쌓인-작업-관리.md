# 8.3.2 큐에 쌓인 작업 관리

> 스레드 하나로 여러개의 작업을 처리하기 힘든상황이 왔을때, 스레드 풀을 사용한다는 점을 이전 장까지 살펴봤었다. 스레드 풀 없이 스레드를 계속해서 생성하는 경우 스레드마다 CPU를 확보하기 위해 대기한다. 이런 이유로 스레드 풀을 사용한다. 하지만 스레드 풀을 사용하더라도, 작업을 처리해내는 속도보다 빠른 속도로 작업이 추가될 때 작업 큐 역시도 견뎌내지 못하는 상황이 발생한다. 8.3.2 절에서는, Collector 에서 제공하는 대표적인 팩토리 메서드들의 작업 큐 관리 방식을 설명하고 있다.<br>
>
> **newCachedThreadPool**<br>
>
> 때에 따라서, 크기가 고정된 풀을 사용할 때보다 `newCachedThreadPool` 팩토리 메서드로 Executor 를 생성해 스레드와 작업큐를 관리하는 것이 효율적일 수도 있다. 예를 들면 다른 작업에 의존성을 갖는 작업을 실행해야 할 때 스레드나 큐의 크기가 제한되어 있으면, 스레드 부족 데드락에 걸릴 가능성이 높다. 이럴 때는 `newCachedThreadPool` 메서드에서 생성하는 것과 같이 스레드 풀의 크기가 제한되지 않은 풀을 사용해야 한다.<br>
>
> 하지만, 이 방식 역시 `newCachedThreadPool`을 사용하지 않는 대안이 있다. ThreadPoolExecutor 를 커스텀으로 생성하는데 아래와 같은 원칙에 따라 생성하면 된다.
>
> - 스레드 풀의 스레드 갯수를 제한
> - 작업 큐로 `SynchronizedQueue` 를 사용
> - 집중 대응 정책으로 호출자 실행 전략을 사용
>
> 집중대응정책은 8.3.3절에서 정리.<br>
>
> **newFixedThreadPool**<br>
>
> 반면, 크기가 고정된 풀을 사용하는 것은 동시에 실행되는 스레드의 수를 제한해야 하는 경우에 현명한 선택이 될 수 있다. 예를 들면 네트웍으로 클라이언트의 요청을 받아 처리하는 애플리케이션의 경우, 크기가 고정되어 있지 않다면 요청이 많아저 부하가 걸릴때 문제가 된다. <br>

<br>

작업을 처리할 수 있는 능력보다 많은 양의 요청이 들어오면 처리하지 못한 요청은 큐에 계속해서 쌓인다. 스레드 풀을 사용하는 경우 Executor 클래스에서 관리하는 큐에 Runnable 로 정의된 작업이 계속해서 쌓인다.<br>

즉, 스레드 풀에 있는 모든 작업이 실행중일때 작업이 등록되면, 스레드 풀 대신 작업은 큐에 Runnable 로 정의된 작업들이 계속해서 쌓이게 된다.<br>

스레드 풀을 사용할 때에 스레드 풀을 사용하지 않는 경우에 비해 문제가 덜 발생하기는 하지만, 스레드 풀을 사용할 경우는, 큐가 꽉 찼을때의 해결방안이 필요하다.<br>

<br>

## 작업큐가 가득 찼을 경우에 대한 해결 방법들

대량의 트래픽이 갑자기 몰리는 경우는 스레드 풀과 작업 큐를 사용해 충분히 유연하게 처리할 수 있다. 이 경우 속도 조절 기능을 사용하거나, 큐에 작업을 쌓아두고 큐에 작업 관리 전략을 적용해야 한다.<br>

스레드 풀이 가득 찼을 때의 해결책은 두가지가 있다. **첫번째**는 **속도조절기능**이고, **두번째**는 **작업 큐에 작업들을 쌓아두는 방식**이다. 스레드 풀의 크기를 제한해두었을 때, 스레드 풀이 가득 차면 작업을 작업 큐에 작업들을 잠시 쌓아둘 수 있다. 이 방식을 작업큐에 작업들을 쌓아두는 방식이라고 부른다. 속도 조절 기능은 클라이언트 측에서 요청의 속도를 조절하는 방식이다.

**속도조절 기능**<br>

계속해서 처리하는 속도보다 빠른 속도로 작업이 추가될 때, 해결방책 중 하나로 책에서는 속도 조절 기능에 대해서도 언급하고 있다. 속도 조절기능은 클라이언트 측에서 속도를 느리게 조절하는 방식인데, 실생활에서는 거의 사용되지 않는 방식이다.<br>

<br>

**작업 큐에 작업들을 쌓아두기**<br>

계속해서 처리하는 속도보다 빠른 속도로 작업이 추가될 때, 또 하나의 해결 방책 중 하나는 작업 큐를 만들어서 작업 대기열처럼 사용하는 것이다. 물론 이것이 만능은 아니다. 스레드 풀이 꽉 찼을때 작업 큐에 등록되는 작업들의 양이 무한대로 늘어날 때 물리적으로 지원 가능한 메모리가 한계치에 도달할 수도 있기 때문이다. 이 경우 거부 정책을 정해서 실행하면 된다.

큐에 대한 작업관리 전략은 세가지가 있다. <br>

1 ) 큐에 크기 제한을 두지 않는 방법 <br>

2 ) 큐의 크기를 제한하는 방법 <br>

3 ) 작업을 스레드에게 직접 넘겨주는 방법 <br>

- 호출자 실행전략을 의미한다. 
- 이 부분은 나중에 정리.

<br>

## 1 ) 큐에 크기 제한을 두지 않는 방법

### newFixedThreadPool, newSingleThreadExecutor

`newFixedThreadPool` 메서드, `newSingleThreadExecutor` 메서드에서 생성하는 스레드 풀은 기본 설정으로 크기가 제한되지 않은 `LinkedBlockingQueue`를 사용한다. 큐의 크기를 제한을 두지 않는 방식을 사용하는 것이 필요한 경우는 상당한 시간이 걸리더라도 데이터를 모두 기록해야 하거나 그런 작업들에 적합하지 않을까 싶다.<br>

스레드 풀에 있는 모든 작업이 실행 중일때 작업이 등록되면, 스레드 풀 대신 작업은 큐에 쌓이게 된다. 이때 작업이 처리되는 속도보다 작업이 추가되는 속도가 더 빠르면 큐에 끝없이 계속해서 작업이 쌓일 수 있다.<br>

이렇게 작업이 끝없이 쌓이는 문제로 인해 `OutOfMemory` 같은 에러가 발생할 수 있는데, 이런 이유로 크기가 제한된 큐를 사용하는 방식이 훨씬 안정적이다. Java 플랫폼에서 제공하고 있는 컬렉션 라이브러리들을 구체적인 예로 들어보면,  `ArrayBlockingQueue` , 크기를 제한해둔 `LinkedBlockingQueue` , `PriorityBlockingQueue` 로 크기가 제한된 큐를 적용하는 것이 안정적인 편이다.<br>

하지만, 큐에 크기 제한을 두지 않는 방식이 그렇게까지 나쁜방식은 아니다. 만약 시간이 걸리더라도 모든 특정시간 내에 무한히 오는 데이터들을 모두 처리해야 하지만, 물리적인 공간이 부족할 경우 `off-heap` 메모리 공간을 사용하도록 유도하거나, 디스크를 읽어들여서 기록해두는 방식의 큐를 사용하는 차선책을 적용하는 방법도 생각해볼 수 있다.<br>

<br>

### newCachedThreadPool

`newCachedThreadPool` 팩토리 메서드는 스레드 풀에 `SynchronousQueue` 를 적용하고 있다. 스레드 갯수가 굉장히 많거나 제한이 거의 없는 경우, 작업을 큐에 쌓는 절차를 생략할 수도 있다. 이런 경우 `SynchronousQueue` 를 사용해 프로듀서에서 생성한 작업을 컨슈머인 스레드에게 직접 전달한다. `newCachedThreadPool` 을 사용할 때 `SynchronouseQueue` 는 큐의 기능보다는, 스레드 간에 작업을 넘겨주는 기능을 충실히 수행한다.<br>

`newCachedThreadPool` 을 사용해 생성한 `ThreadPoolExecutor` 로 스레드를 관리할 때 스레드의 갯수가 최대 크기(`maximumPoolSize`)에 도달하면 `집중 대응 정책(saturation policy)` 에 의해 작업을 거부하게 된다. `newCachedThreadPool` 팩토리 메서드가 사용하는 `SynchronizedQueue` 는 스레드 갯수를 무제한으로 늘릴 수 있는 상태이거나, 넘치는 작업이 있을 때 작업을 마음대로 거부할 수 있어야 한다. 즉, `newCachedThreadPool` 팩토리 메서드를 사용할 경우 아래와 같은 조건을 만족해야 한다.

-  스레드를 무제한으로 늘릴수 있어야 한다.
- 또는 `maximumPoolSize` 를 넘어서는 작업이 있을 경우 마음대로 거부할 수 있어야 한다.

<br>

## 2 ) 큐의 크기를 제한하는 방식

작업을 처리하는 속도보다 요청되는 작업이 추가되는 속도가 더 빠를 때 큐에 쌓아두는데, 이것을 무한히 쌓아둘 경우 메모리 부족 문제가 발생하게 된다. 여기에 대한 해결책 중 하나는 큐의 크기를 제한하고, 큐의 크기가 가득 찼을때 시간이 꽤 지난 데이터가 필요 없다고 생각될 경우 큐에서 강제로 제거하는 방식이 있다. <br>

이 방식은 데이터를 정확하게 기록하거나 하는 작업보다는 실시간으로 어떤 데이터를 계속해서 보여줘야 하는 스트리밍 등의 작업에 적합한 방식이다.<br>

<br>

**장점**<br>

크기가 제한된 큐를 사용하면 자원의 사용량을 제한시킬 수 있다는 장점이 있다. 예를 들면 `OutOfMemory` 와 같은 에러를 발생할 만한 가능성을 줄일 수 있다는 점이 장점이다.<br>

**단점**<br>

큐가 가득 찼을때 새로운 작업을 어떻게 등록해야 할지에 대한 기준을 정해야 하는 문제가 생긴다.<br>

큐에서 제거할 데이터를 추출하는 기준을 마련해야 한다.<br>

<br>

<hr/>

이번 장이 제일 힘들었다. 내용이 여기저기 퍼져 있어서 모아서 정리하는데에 꽤 애를 먹은것 같다.
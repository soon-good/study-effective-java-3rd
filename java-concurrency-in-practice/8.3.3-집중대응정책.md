# 8.3.3 집중대응정책

프로그래머가 작성한 프로그램에서 스레드를 요청하면 JVM은 OS(리눅스,윈도우,맥os)에게 스레드를 요청해 얻어온다. OS가 JVM에게 스레드를 전달해줄때 역시 어느 정도의 지연이 발생한다. OS의 스케쥴링 정책에 따라 비어있는 스레드가 생기기 전까지 JVM이 기다려야 한다. 이런 이유로 JVM 입장에서는 한번 사용한 스레드는 바로 OS에 반납하지 않고 쟁여두는 편이 낫다.<br>

<br>

이렇게 만들어둔 스레드 풀이 가득 찼을때 작업큐라는 것을 사용한다. 생산자/소비자 패턴으로 구현되어 있고, 동작원리는 아래와 같다. 

- `corePoolSize` 만큼의 스레드 풀을 유지하고 있는다. 
- `corePoolSize` 가 꽉 찼을때 작업 큐에 작업을 쌓는다.
- 작업 큐가 꽉 차면, 스레드 갯수를 하나 더 증가시킨다.
  - 이렇게 하면 작업 큐가 소모되는 속도가 빨라진다.

아래는 작업 큐에 작업이 가득 찼을때 집중대응정책(saturation policy)가 동작한다. 집중대응정책은 아래의 여러가지 정책들이 있다.

- 중단(abort) 정책
- 제거(discard) 정책
- 오래된 항목 (oldest discard) 제거 정책
- 호출자(caller runs) 실행 정책

<br>

**대기 정책은 없는지?**<br>

중단, 제거, 호출자 실행 정책 등 3가지의 실행 정책이 있는데, 작업 큐가 가득 찼을 때 execute 메서드가 그저 대기하도록 하는 집중대응 정책은 따로 만들어진 것이 없다. 

다만 아래의 예제처럼 `Semaphore` 를 사용하면 작업 추가 속도를 적절한 범위 내에서 제한할 수 있다.

아래와 같은 방식으로 사용하려면 조건이 있다.

- 큐의 크기에 제한을 두지 않아야 한다.
- 스레드 풀의 스레드 갯수 + 큐의 최대 작업 갯수 = 세마포어의 크기 로 지정

<br>

**Executor 객체 생성시 스레드 풀에 집중대응정책을 설정하는 법**<br>

스레드 풀에 적용할 집중 대응 정책을 선택하거나, 이 외에 여러가지 설정값들을 변경하는 예제코드는 아래와 같다. 생성자에 모두 여러가지 옵션을 지정할 수 있다. (빌더 패턴은 왜 안쓴거야? 하고 생각해봤는데, 인자 누락시 생길수 있는 사이드 이펙트도 있겠구나. 다소 엄격한 생성자를 쓰는게 낫겠구나 하고 생각했다.)<br>

```java
ThreadPoolExecutor executor = 
    new ThreadPoolExecutor(N_THREADS, N_THREADS, 0L, TimeUnit.MILLISECONDS,
                          new LinkedBlockingQueue<Runnable> (CAPACITY));

// 집중 대응 정책을 지정하고 있다.
executor.setRejectedExecutionHandler(
    new ThreadPoolExecutor.CallerRunsPolicy();
)
```

<br>

## abort, 중단 정책

기본적으로 가장 많이 사용하는 집중 대응 정책이다.<br>

호출자에 거부됬다고 예외를 던지는 방식<br>

예외처리 로직은 호출자 스레드 로직 내의 예외 코드에 개발자가 직접 작성해야 한다. 중단 된 작업을 DB나 캐시에 저장해두고 다시 꺼내서 쓰는 것도 나쁘지 않을까 싶기는 하다.<br>

`RejectedExecutionException` 

- 작업 큐에 작업이 가득 찼을 때 execute 메서드에서는 `RejectedExecutionException` 을 던진다.
- execute 메서드를 호출하는 스레드 로직에는 `RejectedExecutionException` 예외 발생시에 대한 로직을 직접 구현해야 한다.

<br>

## discard, 제거 정책

큐에 작업을 더 이상 추가할 수 없을 때 방금 추가하려고 했던 정책을 아무 반응 없이 제거하는 정책이다.<br>

<br>

## discard oldest, 오래된 항목 제거 정책

큐에 쌓은 항목 중 가장 오래되어 다음 번에 실행될 예정이던 작업을 제거하고, 추가하고자 했던 작업을 큐에 다시 추가하는 방식이다.<br>

**우선순위 작업 큐 를 사용할 경우**<br>

작업 큐가 우선순위에 의해 동작하면, 오래된 항목 제거 정책을 사용할 때 큐에 들어있는 항목들 내에서 우선순위가 가장 높은 항목을 제거한다. 따라서 오래된 항목 제거 정책을 우선순위 작업 큐 방식에서 사용하는 것은 좋ㅇ느 선택이 아니다.<br>

<br>

## caller runs, 호출자 실행 정책

작업을 제거하거나, 예외를 던지지 않고 큐의 크기를 초과하면 작업을 프로듀서인 호출자 스레드에게 넘겨서 큐에 작업을 추가하는 속도를 제어하는 방식이다. <br>

책에는 이래 저래 부가적인 설명이 많이 있는데, 내 생각은 이렇다.<br>

근본적으로 RAM 메모리를 사용하는 방식은 저장공간에 한계가 있다. 근본적인 해결책은 아니다.

이 방식은 `호출자에 작업을 넘기면, 호출자가 작업을 작업 큐에 넣는 속도가 늦어지겠지` 하는 추측에 기반한 방식이다. 근거에 의한방식이라기 보다는 추측에 의한 방식이다. 차라리 뒤로 밀리는 작업들은 디스크/DB/캐시에 넣어두는 방식으로 해결하는 것이 좋은 방식이 아닐까 하는 생각해봤다.<br>

<br>

## 개인적인 의견

이렇게 의존성 작업으로 인해 무한으로 대기할 수 밖에 없는 구조라면, 가급적 캐시나 디스크 또는 DB 같은 디스크 저장 구조를 사용하는 것도 나쁘지 않은 선택이 아닐까 하고 조심스럽게 생각해봤다. 모든 작업을 모두 메모리에 담고 있을 필요가 없다. 예를 들면 먹고싶은 음식은 많은데, 한끼에 먹을 음식이 너무 많으면, 소화시킬 수 있는 내 배는 한정적이기에, 다음 끼니에 먹을 음식들을 따로 종이에 적어놔야 한다.<br>

이렇게 종이에 따로 적어놓듯이 디스크/off-heap 저장구조에 데이터를 저장해둘때 해시 또는 시퀀스/킷값을 생성해서 저장해두면 소비자측에서는 이 시퀀스/킷값을 다시 해석해서 작업을 시작할 수도 있다. 예를 들면 생산자에서는 미래에 즉시 처리하지 못할 수도 있는 하나의 작업에 대해 고유하게 인식할 수 있는 킷값(시퀀스)를 부여해 off-heap 또는 디스크에 저장해두고, 소비자 측에서는 이 킷값(시퀀스)를 기반으로 필요한 데이터를 조회해온 후 연산하는 방식으로 하는 것을 예로 들수 있을 것 같다. 속도는 별로 중요하지 않지만, 무한대기에 가까운 작업을 무조건 처리해야만 하는 작업이라면 시도해볼 만 할 듯 하다.<br>

즉, 디스크 or off-heap 에 킷값 기반으로 데이터를 저장해두고, 꺼낼 때는 이 킷값을 기반으로 데이터를 로드해서 무거운 작업을 처리하는 방식이다.<br>

MQ를 사용하는 것은 좋은 해결책일 수도 있다. 하지만, 성격에 따라서 어떤 작업을 처리하느냐에 따라 좋은 해결책은 아닐 수도 있다. RabbitMQ의 경우 7만건 까지만 데이터를 큐에 보관할 수 있다. 그 이후로는 디스크에 저장한다. 디스크에 저장하는 것은 프로그래머가 직접 프로토콜 상의 옵션을 이용해 지정해주면 된다.1초에 7만건이 넘어가는 트래픽을 예로 들수도 있겠다. 물론 아주 심한 경우가 아니라면 클러스터링으로 어느 정도는 해결되고, 소비자의 처리 작업이 엄청 무거운 작업이 아니라면, 소비자 역시도 놀고 있느게 아니기에 적절하게 소비된다는 것이 보장되지 않을까 싶다..<br>

엄청 무거운 작업을 RabbitMQ에 담아놓은 거라면, 소비자 측에서도 RabbitMQ의 데이터가 유실될 경우에 대한 처리 역시 필요하다. 그리고, RabbitMQ를 사용하는 다른 서비스에도 영향을 주게 될지도 고려해야 한다. 마냥 책임감없이 RabbitMQ로 어떻게 처리하면 되겠지 하는 태도는 또 다른 장애를 낳을 수 밖에 없을 수도 있다.<br>

<br>

 
